{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구글 드라이브에 업로드했습니다.\n",
    "df = pd.read_csv('./noise_data_ver1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batch_01_vt/0036.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>batch_01_vt/0045.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>batch_01_vt/0049.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              file_name\n",
       "0  batch_01_vt/0036.jpg\n",
       "1  batch_01_vt/0045.jpg\n",
       "2  batch_01_vt/0049.jpg"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name_list = list(df.file_name)\n",
    "\n",
    "len(file_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.json 정보 불러오기\n",
    "with open(os.path.join(data_dir, 'train.json'), 'r', encoding='UTF-8') as train_json:\n",
    "    train_data = json.load(train_json)\n",
    "    \n",
    "    info = train_data['info']\n",
    "    licenses = train_data['licenses']\n",
    "    categories = train_data['categories']\n",
    "    \n",
    "    train_images = train_data['images']\n",
    "    train_annotations = train_data['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2617/2617 [01:56<00:00, 22.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 images excluded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_images = []\n",
    "new_annotations = []\n",
    "\n",
    "annotation_id = 0\n",
    "image_id = 0\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for img in tqdm(train_images):\n",
    "\n",
    "    file_name = img['file_name']\n",
    "\n",
    "    for ann in train_annotations:\n",
    "\n",
    "        if file_name in file_name_list:\n",
    "            continue\n",
    "        \n",
    "        if ann['image_id'] == img['id']:\n",
    "            new_annotations.append(copy.deepcopy(ann))\n",
    "            new_annotations[-1]['id'] = annotation_id\n",
    "            new_annotations[-1]['image_id'] = image_id\n",
    "            annotation_id += 1\n",
    "\n",
    "    if file_name in file_name_list:\n",
    "        cnt += 1\n",
    "    else:\n",
    "        new_images.append(copy.deepcopy(img))\n",
    "        new_images[-1]['id'] = image_id\n",
    "        image_id += 1\n",
    "\n",
    "print(f'{cnt} images excluded.')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input/data 경로에 train_revised.json으로 저장\n",
    "with open(os.path.join(data_dir, 'train_revised.json'), 'w', encoding='UTF-8') as new_json:\n",
    "    json.dump({ 'info': info, 'licenses': licenses, 'images': new_images, \n",
    "            'annotations': new_annotations, 'categories': categories}, new_json, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val.json 정보 불러오기\n",
    "with open(os.path.join(data_dir, 'val.json'), 'r', encoding='UTF-8') as val_json:\n",
    "    val_data = json.load(val_json)\n",
    "    \n",
    "    info = val_data['info']\n",
    "    licenses = val_data['licenses']\n",
    "    categories = val_data['categories']\n",
    "    \n",
    "    val_images = val_data['images']\n",
    "    val_annotations = val_data['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 655/655 [00:09<00:00, 72.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 images excluded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_images = []\n",
    "new_annotations = []\n",
    "\n",
    "annotation_id = 0\n",
    "image_id = 0\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for img in tqdm(val_images):\n",
    "\n",
    "    file_name = img['file_name']\n",
    "\n",
    "    for ann in val_annotations:\n",
    "\n",
    "        if file_name in file_name_list:\n",
    "            continue\n",
    "        \n",
    "        if ann['image_id'] == img['id']:\n",
    "            new_annotations.append(copy.deepcopy(ann))\n",
    "            new_annotations[-1]['id'] = annotation_id\n",
    "            new_annotations[-1]['image_id'] = image_id\n",
    "            annotation_id += 1\n",
    "\n",
    "    if file_name in file_name_list:\n",
    "        cnt += 1\n",
    "    else:\n",
    "        new_images.append(copy.deepcopy(img))\n",
    "        new_images[-1]['id'] = image_id\n",
    "        image_id += 1\n",
    "\n",
    "print(f'{cnt} images excluded.')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input/data 경로에 val_revised.json으로 저장\n",
    "with open(os.path.join(data_dir, 'val_revised.json'), 'w', encoding='UTF-8') as new_json:\n",
    "    json.dump({ 'info': info, 'licenses': licenses, 'images': new_images, \n",
    "            'annotations': new_annotations, 'categories': categories}, new_json, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2775/2775 [02:01<00:00, 22.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train0: 54 images excluded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 692/692 [00:10<00:00, 68.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val0: 22 images excluded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2771/2771 [02:05<00:00, 22.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train1: 61 images excluded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 696/696 [00:09<00:00, 73.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val1: 15 images excluded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2774/2774 [02:07<00:00, 21.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train2: 67 images excluded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 693/693 [00:08<00:00, 79.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val2: 9 images excluded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2770/2770 [02:06<00:00, 21.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train3: 63 images excluded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 697/697 [00:09<00:00, 75.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val3: 13 images excluded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2778/2778 [02:05<00:00, 22.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train4: 59 images excluded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 689/689 [00:09<00:00, 70.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val4: 17 images excluded.\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../../../data/stratified_kfold'\n",
    "\n",
    "for i in range(5):\n",
    "    # train.json 정보 불러오기\n",
    "    with open(os.path.join(data_dir, f'train{i}.json'), 'r', encoding='UTF-8') as train_json:\n",
    "        train_data = json.load(train_json)\n",
    "    \n",
    "        info = train_data['info']\n",
    "        licenses = train_data['licenses']\n",
    "        categories = train_data['categories']\n",
    "    \n",
    "        train_images = train_data['images']\n",
    "        train_annotations = train_data['annotations']\n",
    "    \n",
    "    new_images = []\n",
    "    new_annotations = []\n",
    "\n",
    "    annotation_id = 0\n",
    "    image_id = 0\n",
    "\n",
    "    cnt = 0\n",
    "\n",
    "    for img in tqdm(train_images):\n",
    "\n",
    "        file_name = img['file_name']\n",
    "\n",
    "        for ann in train_annotations:\n",
    "\n",
    "            if file_name in file_name_list:\n",
    "                continue\n",
    "        \n",
    "            if ann['image_id'] == img['id']:\n",
    "                new_annotations.append(copy.deepcopy(ann))\n",
    "                new_annotations[-1]['id'] = annotation_id\n",
    "                new_annotations[-1]['image_id'] = image_id\n",
    "                annotation_id += 1\n",
    "\n",
    "        if file_name in file_name_list:\n",
    "            cnt += 1\n",
    "        else:\n",
    "            new_images.append(copy.deepcopy(img))\n",
    "            new_images[-1]['id'] = image_id\n",
    "            image_id += 1\n",
    "\n",
    "    print(f'train{i}: {cnt} images excluded.')\n",
    "\n",
    "    # input/data/stratified_kfold 경로에 train_revised.json으로 저장\n",
    "    with open(os.path.join(data_dir, f'train{i}_revised.json'), 'w', encoding='UTF-8') as new_json:\n",
    "        json.dump({ 'info': info, 'licenses': licenses, 'images': new_images, \n",
    "            'annotations': new_annotations, 'categories': categories}, new_json, indent=2)\n",
    "\n",
    "    \n",
    "    # val.json 정보 불러오기\n",
    "    with open(os.path.join(data_dir, f'val{i}.json'), 'r', encoding='UTF-8') as val_json:\n",
    "        val_data = json.load(val_json)\n",
    "    \n",
    "        info = val_data['info']\n",
    "        licenses = val_data['licenses']\n",
    "        categories = val_data['categories']\n",
    "    \n",
    "        val_images = val_data['images']\n",
    "        val_annotations = val_data['annotations']\n",
    "\n",
    "    new_images = []\n",
    "    new_annotations = []\n",
    "\n",
    "    annotation_id = 0\n",
    "    image_id = 0\n",
    "\n",
    "    cnt = 0\n",
    "\n",
    "    for img in tqdm(val_images):\n",
    "\n",
    "        file_name = img['file_name']\n",
    "\n",
    "        for ann in val_annotations:\n",
    "\n",
    "            if file_name in file_name_list:\n",
    "                continue\n",
    "        \n",
    "            if ann['image_id'] == img['id']:\n",
    "                new_annotations.append(copy.deepcopy(ann))\n",
    "                new_annotations[-1]['id'] = annotation_id\n",
    "                new_annotations[-1]['image_id'] = image_id\n",
    "                annotation_id += 1\n",
    "\n",
    "        if file_name in file_name_list:\n",
    "            cnt += 1\n",
    "        else:\n",
    "            new_images.append(copy.deepcopy(img))\n",
    "            new_images[-1]['id'] = image_id\n",
    "            image_id += 1\n",
    "\n",
    "    print(f'val{i}: {cnt} images excluded.')\n",
    "            \n",
    "    # input/data 경로에 val_revised.json으로 저장\n",
    "    with open(os.path.join(data_dir, f'val{i}_revised.json'), 'w', encoding='UTF-8') as new_json:\n",
    "        json.dump({ 'info': info, 'licenses': licenses, 'images': new_images, \n",
    "            'annotations': new_annotations, 'categories': categories}, new_json, indent=2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b61334fc597f37c4afc7c0cbc444a32addc4879ea1f88dd9327d69e6c1a401a2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
