{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google drive data 폴더에 있는 ver3 내부 csv 파일들을 받아야 합니다.\n",
    "def data_cleasing(json_file):\n",
    "    print(f'***{json_file}***')\n",
    "\n",
    "\n",
    "    # 전처리할 데이터 불러오기\n",
    "    data_dir = '../../../data/stratified_kfold'\n",
    "\n",
    "    with open(os.path.join(data_dir, json_file), 'r', encoding='UTF-8') as data_json:\n",
    "        data = json.load(data_json)\n",
    "    \n",
    "        info = data['info']\n",
    "        licenses = data['licenses']\n",
    "        categories = data['categories']\n",
    "    \n",
    "        images = data['images']\n",
    "        annotations = data['annotations']\n",
    "\n",
    "    # 제외할 이미지 목록 불러오기\n",
    "    df_image_exclude = pd.read_csv('./ver3/image.csv')\n",
    "    img_exclude_list = list(df_image_exclude.file_name)\n",
    "\n",
    "    # 이미지 제외하기\n",
    "    new_images = []\n",
    "    new_annotations = []\n",
    "\n",
    "    annotation_id = 0\n",
    "    image_id = 0\n",
    "\n",
    "    cnt = 0\n",
    "\n",
    "    print('excluding images...')\n",
    "    for img in tqdm(images):\n",
    "\n",
    "        file_name = img['file_name']\n",
    "\n",
    "        for ann in annotations:\n",
    "            # 제외할 목록에 있다면 넘어가기\n",
    "            if file_name in img_exclude_list:\n",
    "                continue\n",
    "        \n",
    "            if ann['image_id'] == img['id']:\n",
    "                new_annotations.append(copy.deepcopy(ann))\n",
    "                new_annotations[-1]['id'] = annotation_id\n",
    "                new_annotations[-1]['image_id'] = image_id\n",
    "                annotation_id += 1\n",
    "\n",
    "        if file_name in img_exclude_list:\n",
    "            cnt += 1\n",
    "        else:\n",
    "            new_images.append(copy.deepcopy(img))\n",
    "            new_images[-1]['id'] = image_id\n",
    "            image_id += 1\n",
    "\n",
    "    print(f'{cnt} images excluded.')\n",
    "\n",
    "    # 잘못된 category_id 변경해주기\n",
    "    df_anno = pd.read_csv('./ver3/anno.csv')\n",
    "\n",
    "    wrong_anno_files = list(df_anno.file_name)\n",
    "    wrong_cats = df_anno.category\n",
    "    \n",
    "    cnt = 0\n",
    "\n",
    "    for f, c in zip(wrong_anno_files, wrong_cats):\n",
    "        # Plastic bag 내부 object의 category가 2가지인 경우도 있다.\n",
    "        c = c.split(', ')\n",
    "\n",
    "        for img in new_images:\n",
    "            # revise해야할 file_name과 겹친다면\n",
    "            if f == img['file_name']:\n",
    "                for i in range(len(new_annotations)):\n",
    "                    if new_annotations[i]['image_id'] == img['id']:\n",
    "                        # 바뀌어야 할 category와 같다면 (Plastic bag 내부의 object라면)\n",
    "                        if new_annotations[i]['category_id'] == int(c[0]):\n",
    "                            new_annotations[i]['category_id'] = 8\n",
    "                            cnt += 1\n",
    "\n",
    "                        if len(c) > 1:\n",
    "                            if new_annotations[i]['category_id'] == int(c[1]):\n",
    "                                new_annotations[i]['category_id'] = 8\n",
    "                                cnt += 1\n",
    "    \n",
    "    print(f'{cnt} categories changed.')\n",
    "\n",
    "    # Plastic bag 내부 object category가 외부 object category와 겹친다면,\n",
    "    # Plastic bag bbox 안 object의 category 변경하기\n",
    "    df_bbox = pd.read_csv('./ver3/bbox.csv')\n",
    "\n",
    "    wrong_img_id = []\n",
    "\n",
    "    for img in new_images:\n",
    "        if img['file_name'] in list(df_bbox.file_name):\n",
    "            wrong_img_id.append(img['id'])\n",
    "\n",
    "    cnt = 0\n",
    "\n",
    "    for img_id in wrong_img_id:\n",
    "        for i in range(len(new_annotations)):\n",
    "            # Plastic bag의 bbox 구하기\n",
    "            if img_id == new_annotations[i]['image_id'] and new_annotations[i]['category_id'] == 8:\n",
    "                bbox_pb = new_annotations[i]['bbox']\n",
    "\n",
    "                x_min_pb = bbox_pb[0]\n",
    "                y_min_pb = bbox_pb[1]\n",
    "                x_max_pb = x_min_pb + bbox_pb[2]\n",
    "                y_max_pb = y_min_pb + bbox_pb[3]\n",
    "\n",
    "                for j in range(len(new_annotations)):\n",
    "                    if j != i and new_annotations[j]['image_id'] == img_id:\n",
    "                        bbox = new_annotations[j]['bbox']\n",
    "\n",
    "                        x_min = bbox[0]\n",
    "                        y_min = bbox[1]\n",
    "                        x_max = x_min + bbox[2]\n",
    "                        y_max = y_min + bbox[3]\n",
    "\n",
    "                        # Plastic bag bbox 안에 object가 있다면 Plastic bag으로 바꿔주기\n",
    "                        if x_min_pb <= x_min and y_min_pb <= y_min and x_max_pb >= x_max and y_max_pb >= y_max:\n",
    "                            new_annotations[j]['category_id'] = 8\n",
    "                            cnt += 1\n",
    "\n",
    "    print(f'{cnt} categories changed.')\n",
    "\n",
    "    json_file = json_file.split('.')[0]\n",
    "    print(f'saving revised {json_file}...')\n",
    "    print()\n",
    "\n",
    "    with open(os.path.join(data_dir, f'{json_file}_revised.json'), 'w', encoding='UTF-8') as new_json:\n",
    "        json.dump({ 'info': info, 'licenses': licenses, 'images': new_images, \n",
    "            'annotations': new_annotations, 'categories': categories}, new_json, indent=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***train0.json***\n",
      "excluding images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2775/2775 [01:18<00:00, 35.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 images excluded.\n",
      "47 categories changed.\n",
      "16 categories changed.\n",
      "saving revised train0...\n",
      "\n",
      "***train1.json***\n",
      "excluding images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2771/2771 [01:20<00:00, 34.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 images excluded.\n",
      "65 categories changed.\n",
      "15 categories changed.\n",
      "saving revised train1...\n",
      "\n",
      "***train2.json***\n",
      "excluding images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2774/2774 [01:21<00:00, 34.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 images excluded.\n",
      "54 categories changed.\n",
      "23 categories changed.\n",
      "saving revised train2...\n",
      "\n",
      "***train3.json***\n",
      "excluding images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2770/2770 [01:20<00:00, 34.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 images excluded.\n",
      "48 categories changed.\n",
      "27 categories changed.\n",
      "saving revised train3...\n",
      "\n",
      "***train4.json***\n",
      "excluding images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2778/2778 [01:18<00:00, 35.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 images excluded.\n",
      "46 categories changed.\n",
      "27 categories changed.\n",
      "saving revised train4...\n",
      "\n",
      "***val0.json***\n",
      "excluding images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 692/692 [00:07<00:00, 92.78it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 images excluded.\n",
      "18 categories changed.\n",
      "11 categories changed.\n",
      "saving revised val0...\n",
      "\n",
      "***val1.json***\n",
      "excluding images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 696/696 [00:06<00:00, 100.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 images excluded.\n",
      "0 categories changed.\n",
      "12 categories changed.\n",
      "saving revised val1...\n",
      "\n",
      "***val2.json***\n",
      "excluding images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 693/693 [00:06<00:00, 102.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 images excluded.\n",
      "11 categories changed.\n",
      "4 categories changed.\n",
      "saving revised val2...\n",
      "\n",
      "***val3.json***\n",
      "excluding images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 697/697 [00:06<00:00, 103.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 images excluded.\n",
      "17 categories changed.\n",
      "0 categories changed.\n",
      "saving revised val3...\n",
      "\n",
      "***val4.json***\n",
      "excluding images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 689/689 [00:07<00:00, 94.45it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 images excluded.\n",
      "19 categories changed.\n",
      "0 categories changed.\n",
      "saving revised val4...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_cleasing('train0.json')\n",
    "data_cleasing('train1.json')\n",
    "data_cleasing('train2.json')\n",
    "data_cleasing('train3.json')\n",
    "data_cleasing('train4.json')\n",
    "data_cleasing('val0.json')\n",
    "data_cleasing('val1.json')\n",
    "data_cleasing('val2.json')\n",
    "data_cleasing('val3.json')\n",
    "data_cleasing('val4.json')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
