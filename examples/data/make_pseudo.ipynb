{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import shutil\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 파일 경로 수정\n",
    "submission = pd.read_csv('/opt/ml/input/develop/submission/swinL_multiscale.csv')\n",
    "data_dir = '/opt/ml/input/data'\n",
    "train_json_path = '/opt/ml/input/data/new_train_all_anno_excluded.json'\n",
    "pseudo_json_path = '/opt/ml/input/data/pseudo.json' # 저장될 경로\n",
    "with open(train_json_path, 'r') as train_json:\n",
    "    train_dict = json.load(train_json)\n",
    "\n",
    "pseudo_dict = {}\n",
    "pseudo_dict[\"info\"] = train_dict['info']\n",
    "pseudo_dict['licenses'] = train_dict['licenses']\n",
    "pseudo_dict['images'] = train_dict['images']\n",
    "pseudo_dict['annotations'] = train_dict['annotations']\n",
    "pseudo_dict['categories'] = train_dict['categories']\n",
    "\n",
    "img_dir = '/opt/ml/input/data/pseudo_mmseg/img_dir'\n",
    "ann_dir = '/opt/ml/input/data/pseudo_mmseg/ann_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pseudo_dict['images']))\n",
    "print(len(pseudo_dict['annotations']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sol 2\n",
    ".csv => 256x256 reshape => Image로 변환 후 jpg, png로 저장 후 mmseg에서 학습\n",
    "기존 mmseg의 ann_dir, img_dir은 위의 img_dir, ann_dir 변수 대로 복사하였음.\n",
    "그럼 kfold는 어떻게 하지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_img=0\n",
    "# start_ann=0\n",
    "# for i in tqdm(range(len(submission))):\n",
    "#     cur = submission.iloc[i,:]\n",
    "#     old_path = os.path.join(data_dir, cur['image_id'])\n",
    "#     new_path = os.path.join(img_dir, str(start_img + i).zfill(4) + '.jpg')\n",
    "\n",
    "#     shutil.copyfile(old_path, new_path)\n",
    "    \n",
    "#     arr = np.array(cur['PredictionString'].split()).reshape(256, 256)\n",
    "#     mask = Image.fromarray(np.uint8(arr))\n",
    "#     mask = mask.resize((512, 512), Image.LANCZOS)\n",
    "#     plt.imshow(mask)\n",
    "#     new_ann_path = os.path.join(ann_dir, str(start_ann + i).zfill(4) + '.png')\n",
    "#     mask.save(new_ann_path)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_id                                         batch_01_vt/0028.jpg\n",
      "PredictionString    0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(submission.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sol 1\n",
    "object detection 처럼 .csv를 coco format으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_img_id = train_dict['images'][-1]['id'] + 1\n",
    "start_ann_id = train_dict['annotations'][-1]['id'] + 1\n",
    "\n",
    "for i in tqdm(range(len(submission))):\n",
    "    # submission 형태는 위의 print 참고\n",
    "    now = submission.iloc[i] # i 번째 행 가져옴\n",
    "    tmp_img_dict = {'width': 512, 'height': 512,\n",
    "     'file_name': now['image_id'], 'license': 0,\n",
    "      'flickr_url': None, 'coco_url': None, \n",
    "      'date_captured': '2021-01-06 09:09:58', 'id': start_img_id}\n",
    "    \n",
    "    pseudo_dict['images'].append(tmp_img_dict)\n",
    "\n",
    "    # 256x256 arr에 prediction 저장\n",
    "    arr = np.array(now['PredictionString'].split()).reshape(256,256)\n",
    "    # 카테고리 별 좌표 저장할 변수\n",
    "    category_arr = [[] for i in range(11)]\n",
    "\n",
    "    # 512x512로 바꾸기 위해 arr을 Image로 바꾼 후\n",
    "    # resize(512,512) 후 다시 int로 바꾸었음\n",
    "    mask = Image.fromarray(np.uint8(arr))\n",
    "    mask = mask.resize((512, 512), Image.LANCZOS)\n",
    "    plt.imshow(mask)\n",
    "    arr = np.uint8(mask)\n",
    "    arr = np.array(arr, dtype='int')\n",
    "\n",
    "    # category 별로 좌표 저장\n",
    "    for x in range(512):\n",
    "      for y in range(512):\n",
    "        if 0 < arr[x][y] and arr[x][y] < 11:\n",
    "          # 좌표니까 y, x로 저장하였음\n",
    "          category_arr[arr[x][y]].append(y)\n",
    "          category_arr[arr[x][y]].append(x)\n",
    "    # 1~10 카테고리 탐색\n",
    "    for n in range(1,11):\n",
    "      # baseline이랑 똑같이 만드려고 category_arr[n]을 list로 감싸주었음\n",
    "      tmp = []\n",
    "      tmp.append(category_arr[n])\n",
    "      # area, bbox, iscrowd는 아무거나\n",
    "      tmp_ann_dict = {\n",
    "        'image_id': start_img_id,\n",
    "        'category_id': n,\n",
    "        \"segmentation\": np.array(tmp, dtype=np.int8), \n",
    "        \"area\": 0, \n",
    "        \"bbox\": np.array([100,100,101,101], dtype=np.float32), \n",
    "        \"iscrowd\": 0,\n",
    "        'id': start_ann_id}\n",
    "      # segmentation이 존재해야 annotation에 저장\n",
    "      if len(tmp_ann_dict['segmentation'][0]):\n",
    "        pseudo_dict['annotations'].append(tmp_ann_dict)\n",
    "        start_ann_id+=1\n",
    "\n",
    "    start_img_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pseudo_dict['images']))\n",
    "print(len(pseudo_dict['annotations']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pseudo_json_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(pseudo_dict, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
