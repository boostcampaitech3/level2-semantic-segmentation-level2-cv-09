{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/opt/ml/input/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_all.json 정보 불러오기\n",
    "with open(os.path.join(data_dir, 'train_all.json'), 'r', encoding='UTF-8') as train_json:\n",
    "    train_data = json.load(train_json)\n",
    "    \n",
    "    info = train_data['info']\n",
    "    licenses = train_data['licenses']\n",
    "    categories = train_data['categories']\n",
    "    \n",
    "    train_images = train_data['images']\n",
    "    train_annotations = train_data['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.json 정보 불러오기\n",
    "with open(os.path.join(data_dir, 'batch_03/data.json'), 'r', encoding='UTF-8') as leaked_json:\n",
    "    leaked_data = json.load(leaked_json)\n",
    "    \n",
    "    leaked_images = leaked_data['images']\n",
    "    leaked_annotations = leaked_data['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leaked_data.txt는 구글 드라이브에 업로드해놨습니다.\n",
    "with open(os.path.join(data_dir, 'leaked_data.txt'), 'r') as f:\n",
    "    leaked_files = f.readlines()\n",
    "    leaked_files = list(map(lambda x : x.strip(), leaked_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_images = copy.deepcopy(train_images)\n",
    "new_annotations = copy.deepcopy(train_annotations)\n",
    "\n",
    "# 추가 시 사용할 annotation_id\n",
    "annotation_id = train_annotations[-1]['id'] + 1\n",
    "\n",
    "# 추가 시 사용할 image_id\n",
    "image_id = train_images[-1]['id'] + 1\n",
    "\n",
    "# 유출 된 annotation 합치기\n",
    "for img in leaked_images:\n",
    "    if img['file_name'] in leaked_files:\n",
    "        flag = False\n",
    "        for ann in leaked_annotations:\n",
    "            if ann['category_id'] == 0:\n",
    "                flag = True\n",
    "                break\n",
    "        if flag: continue\n",
    "\n",
    "        for ann in leaked_annotations:\n",
    "            if ann['image_id'] == img['id']:\n",
    "                new_annotations.append(copy.deepcopy(ann))\n",
    "                # 추가된 annotation의 id와 image_id 수정\n",
    "                new_annotations[-1]['id'] = annotation_id\n",
    "                new_annotations[-1]['image_id'] = image_id\n",
    "                annotation_id += 1\n",
    "\n",
    "        new_images.append(copy.deepcopy(img))\n",
    "        #추가된 images의 id 수정\n",
    "        new_images[-1]['id'] = image_id\n",
    "        image_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input/data 경로에 new_train_all.json으로 저장\n",
    "with open('/opt/ml/input/data/new_train_all_img_excluded.json', 'w', encoding='UTF-8') as new_json:\n",
    "        json.dump({ 'info': info, 'licenses': licenses, 'images': new_images, \n",
    "            'annotations': new_annotations, 'categories': categories}, new_json, indent=2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
